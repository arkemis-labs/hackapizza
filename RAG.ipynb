{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ibm-watsonx-ai\n",
    "!pip install sentence_transformers\n",
    "!pip install PyPDF2\n",
    "!pip install docling\n",
    "!pip install faiss-cpu\n",
    "!pip install ibm_cloud_sdk_core\n",
    "!pip install ibm-watson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import markdown\n",
    "import os\n",
    "from docling.document_converter import DocumentConverter\n",
    "import pandas as pd\n",
    "import json\n",
    "import openai\n",
    "import time\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ENDPOINT_URL =      os.getenv('ENDPOINT_URL')\n",
    "API_KEY =           os.getenv('API_KEY')\n",
    "PROJECT_ID =        os.getenv('PROJECT_ID')\n",
    "openai.api_key =    os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "def chat(query, max_tokens=8000):\n",
    "    credentials = Credentials(\n",
    "        url=ENDPOINT_URL,\n",
    "        api_key=API_KEY\n",
    "    )\n",
    "\n",
    "    model = ModelInference(\n",
    "        model_id=\"meta-llama/llama-3-3-70b-instruct\",\n",
    "        credentials=credentials,\n",
    "        project_id=PROJECT_ID,\n",
    "        params={\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    result = model.chat(messages=[{'role': 'user', 'content': query}])\n",
    "\n",
    "    answer = result['choices'][0]['message']['content']\n",
    "\n",
    "    return answer\n",
    "\n",
    "def gpt_chat(prompts: list,\n",
    "         model: str = \"gpt-4o-mini\",\n",
    "         temperature: float = 0.6,\n",
    "         max_tokens: int = 8000,\n",
    "         frequency_penalty: float = 0.0,\n",
    "         presence_penalty: float = 0.0,\n",
    "         format: str = \"text\",\n",
    "         clean_output: bool = True,\n",
    "         verbose: bool = True) -> tuple:\n",
    "\n",
    "    if not isinstance(prompts[0], dict):\n",
    "        messages = []\n",
    "        len_prompt = len(prompts)\n",
    "\n",
    "        if len_prompt == 1:\n",
    "            messages.append({\"role\": \"system\",  \"content\": \"Sei un ottimo assistente.\"})\n",
    "            messages.append({\"role\": \"user\",    \"content\": prompts[0]})\n",
    "        \n",
    "        else:\n",
    "            for i in range(len_prompt):\n",
    "                if i == 0:\n",
    "                    messages.append({\"role\": \"system\",      \"content\": prompts[i]})\n",
    "                elif i%2 != 0:\n",
    "                    messages.append({\"role\": \"user\",        \"content\": prompts[i]})\n",
    "                else:\n",
    "                    messages.append({\"role\": \"assistant\",   \"content\": prompts[i]})\n",
    "    else:\n",
    "        messages = prompts\n",
    "    \n",
    "    # Setting output to JSON or STRING\n",
    "    if format == \"json\":\n",
    "        if model == \"gpt-4o\":\n",
    "            model = \"gpt-4o\"\n",
    "\n",
    "        elif model == \"gpt-4\":\n",
    "            model = \"gpt-4-turbo\"\n",
    "\n",
    "        else:\n",
    "            model = \"gpt-4o-mini\"\n",
    "\n",
    "        output_format = \"json_object\"\n",
    "\n",
    "    elif format == \"text\":\n",
    "        model = model\n",
    "        output_format = \"text\"\n",
    "    \n",
    "    else:\n",
    "        raise Exception(f\"The format `{format}` is not compatible. Choose between `text` or `json`.\")\n",
    "\n",
    "\n",
    "    # Iterating chat N times\n",
    "    retries = 0\n",
    "    max_retries = 3\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            print(f'\\n\\tAsking {model} using a temperature of {temperature}...\\n')\n",
    "            completion = openai.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=temperature,\n",
    "                timeout=300,\n",
    "                #functions=functions,\n",
    "                frequency_penalty=frequency_penalty,\n",
    "                presence_penalty=presence_penalty,\n",
    "                response_format={\"type\": output_format}\n",
    "            )\n",
    "\n",
    "            answer = completion.choices[0].message.content\n",
    "\n",
    "            ## Cleaning output\n",
    "            if clean_output:\n",
    "                answer = answer.replace('\\n\\n','\\n')\n",
    "                answer = answer.replace('\\n',' ') \n",
    "\n",
    "                if format == \"json\":\n",
    "                    try:\n",
    "                        answer = json.loads(answer)\n",
    "                    except:\n",
    "                        answer = answer\n",
    "       \n",
    "                else:\n",
    "                    ## Removing double or single quotes\n",
    "                    answer = answer.strip(\"\\\"\")\n",
    "                    answer = answer.strip(\"\\'\")\n",
    "\n",
    "            if verbose:\n",
    "                print(answer)\n",
    "\n",
    "            return answer, completion\n",
    "\n",
    "        except openai.APIError as e:\n",
    "            print(e)\n",
    "            print('Timeout error, retrying...')\n",
    "            retries += 1\n",
    "            time.sleep(5 * retries)\n",
    "\n",
    "    return print(\"Server is not responding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already extracted.\n",
      "File already extracted.\n",
      "File already extracted.\n",
      "File already extracted.\n",
      "File already extracted.\n",
      "File already extracted.\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf_OLD(pdf_path):\n",
    "    converter = DocumentConverter()\n",
    "    result = converter.convert(pdf_path)\n",
    "    output = result.document.export_to_markdown()\n",
    "    return output\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "\n",
    "    # Itera sulle pagine e estrai il testo\n",
    "    for page_num, page in enumerate(reader.pages, start=1):\n",
    "        text += page.extract_text()\n",
    "        text += \"\\n\"\n",
    "    \n",
    "    return text\n",
    "\n",
    "def extract_text_from_html(html_path):\n",
    "    with open(html_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "        output = soup.get_text()\n",
    "        return output\n",
    "\n",
    "def extract_text_from_md(md_path):\n",
    "    with open(md_path, 'r', encoding='utf-8') as file:\n",
    "        html = markdown.markdown(file.read())\n",
    "        output = BeautifulSoup(html, 'html.parser').get_text()\n",
    "        return output\n",
    "    \n",
    "def extract_text_from_docx(docx_path):\n",
    "    converter = DocumentConverter()\n",
    "    result = converter.convert(docx_path)\n",
    "    output = result.document.export_to_text()\n",
    "    return output\n",
    "\n",
    "def extract_text_from_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    output = df.to_string()\n",
    "    return output\n",
    "\n",
    "def save_text(text, output_path):\n",
    "    with open(output_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "\n",
    "# Directory di input/output\n",
    "folders = ['blogpost', 'codice_galattico', 'menu', 'misc']\n",
    "\n",
    "for folder in folders:\n",
    "    input_dir = f\"dataset/{folder}\"\n",
    "    output_dir = f\"converted_dataset/{folder}\"\n",
    "\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        file_path =     os.path.join(input_dir, file_name)\n",
    "        output_path =   os.path.join(output_dir, f\"{os.path.splitext(file_name)[0]}.txt\")\n",
    "\n",
    "        if not os.path.isfile(output_path):\n",
    "            if file_name.endswith('.pdf'):\n",
    "                text = extract_text_from_pdf(file_path)\n",
    "            elif file_name.endswith('.html'):\n",
    "                text = extract_text_from_html(file_path)\n",
    "            elif file_name.endswith('.md'):\n",
    "                text = extract_text_from_md(file_path)\n",
    "            elif file_name.endswith('.docx'):\n",
    "                text = extract_text_from_docx(file_path)\n",
    "            elif file_name.endswith('.csv'):\n",
    "                text = extract_text_from_csv(file_path)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            print(\"File already extracted.\")\n",
    "            continue\n",
    "\n",
    "        save_text(text, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 26\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m## First section\u001b[39;00m\n\u001b[1;32m     15\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mSegui attentamente queste istruzioni. Devi estrarre le seguenti informazioni dal <DOCUMENTO> che ti fornirò.\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124mCrea un file JSON, ovvero una lista di dizionari, uno per ogni ricetta, composto da 3 chiavi:\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124m- *chef*: stringa\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124m<DOCUMENTO>: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplitted_text[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 26\u001b[0m output_0 \u001b[38;5;241m=\u001b[39m chat(request)\n\u001b[1;32m     27\u001b[0m output_0 \u001b[38;5;241m=\u001b[39m output_0\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     28\u001b[0m output_0 \u001b[38;5;241m=\u001b[39m output_0\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[53], line 38\u001b[0m, in \u001b[0;36mchat\u001b[0;34m(query, max_tokens)\u001b[0m\n\u001b[1;32m     23\u001b[0m credentials \u001b[38;5;241m=\u001b[39m Credentials(\n\u001b[1;32m     24\u001b[0m     url\u001b[38;5;241m=\u001b[39mENDPOINT_URL,\n\u001b[1;32m     25\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mAPI_KEY\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m ModelInference(\n\u001b[1;32m     29\u001b[0m     model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/llama-3-3-70b-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     30\u001b[0m     credentials\u001b[38;5;241m=\u001b[39mcredentials,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     }\n\u001b[1;32m     36\u001b[0m )\n\u001b[0;32m---> 38\u001b[0m result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mchat(messages\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: query}])\n\u001b[1;32m     40\u001b[0m answer \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m answer\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ibm_watsonx_ai/foundation_models/inference/model_inference.py:277\u001b[0m, in \u001b[0;36mModelInference.chat\u001b[0;34m(self, messages, params, tools, tool_choice, tool_choice_option)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(\n\u001b[1;32m    274\u001b[0m         Messages\u001b[38;5;241m.\u001b[39mget_message(message_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_deployment_scenario\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    275\u001b[0m     )\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference\u001b[38;5;241m.\u001b[39mchat(\n\u001b[1;32m    278\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m    279\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    280\u001b[0m     tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m    281\u001b[0m     tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[1;32m    282\u001b[0m     tool_choice_option\u001b[38;5;241m=\u001b[39mtool_choice_option,\n\u001b[1;32m    283\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ibm_watsonx_ai/foundation_models/inference/fm_model_inference.py:129\u001b[0m, in \u001b[0;36mFMModelInference.chat\u001b[0;34m(self, messages, params, tools, tool_choice, tool_choice_option)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchat\u001b[39m(\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    118\u001b[0m     messages: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m     tool_choice_option: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    123\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m    125\u001b[0m     text_chat_url \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mservice_instance\u001b[38;5;241m.\u001b[39m_href_definitions\u001b[38;5;241m.\u001b[39mget_fm_chat_href(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    127\u001b[0m     )\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_chat_payload(\n\u001b[1;32m    130\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m    131\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    132\u001b[0m         generate_url\u001b[38;5;241m=\u001b[39mtext_chat_url,\n\u001b[1;32m    133\u001b[0m         tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m    134\u001b[0m         tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[1;32m    135\u001b[0m         tool_choice_option\u001b[38;5;241m=\u001b[39mtool_choice_option,\n\u001b[1;32m    136\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ibm_watsonx_ai/foundation_models/inference/base_model_inference.py:287\u001b[0m, in \u001b[0;36mBaseModelInference._send_chat_payload\u001b[0;34m(self, messages, params, generate_url, tools, tool_choice, tool_choice_option)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_http_client, httpx\u001b[38;5;241m.\u001b[39mClient):\n\u001b[1;32m    285\u001b[0m     post_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_retry_status_codes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _RETRY_STATUS_CODES\n\u001b[0;32m--> 287\u001b[0m response_scoring \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_http_client\u001b[38;5;241m.\u001b[39mpost(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpost_params)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_response(\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    292\u001b[0m     response_scoring,\n\u001b[1;32m    293\u001b[0m     _field_to_hide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    294\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ibm_watsonx_ai/_wrappers/requests.py:426\u001b[0m, in \u001b[0;36mHTTPXClient.post\u001b[0;34m(self, url, content, json, headers, params, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m headers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m headers\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    424\u001b[0m         headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 426\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpost(\n\u001b[1;32m    427\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    428\u001b[0m     content\u001b[38;5;241m=\u001b[39mcontent,\n\u001b[1;32m    429\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    430\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    432\u001b[0m )\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpx/_client.py:1157\u001b[0m, in \u001b[0;36mClient.post\u001b[0;34m(self, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1138\u001b[0m     url: URL \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     extensions: RequestExtensions \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1151\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;124;03m    Send a `POST` request.\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \n\u001b[1;32m   1155\u001b[0m \u001b[38;5;124;03m    **Parameters**: See `httpx.request`.\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m   1158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1159\u001b[0m         url,\n\u001b[1;32m   1160\u001b[0m         content\u001b[38;5;241m=\u001b[39mcontent,\n\u001b[1;32m   1161\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m   1162\u001b[0m         files\u001b[38;5;241m=\u001b[39mfiles,\n\u001b[1;32m   1163\u001b[0m         json\u001b[38;5;241m=\u001b[39mjson,\n\u001b[1;32m   1164\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m   1165\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1166\u001b[0m         cookies\u001b[38;5;241m=\u001b[39mcookies,\n\u001b[1;32m   1167\u001b[0m         auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m   1168\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m   1169\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m   1170\u001b[0m         extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m   1171\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpx/_client.py:837\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    822\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m    824\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    825\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    826\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    835\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    836\u001b[0m )\n\u001b[0;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(request, auth\u001b[38;5;241m=\u001b[39mauth, follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[1;32m    927\u001b[0m     request,\n\u001b[1;32m    928\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m    929\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    930\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m    931\u001b[0m )\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[1;32m    955\u001b[0m         request,\n\u001b[1;32m    956\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    957\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m    958\u001b[0m     )\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ibm_watsonx_ai/_wrappers/requests.py:507\u001b[0m, in \u001b[0;36mHTTPXRetryTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    505\u001b[0m timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 507\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    509\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    245\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(\n\u001b[1;32m    197\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/ssl.py:1296\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1294\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1295\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/ssl.py:1169\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = 'dataset_md/Eco di Pandora.txt'\n",
    "path = 'dataset_md/L Eco dei Sapori.txt'\n",
    "path = 'dataset_md/L Essenza delle Dune.txt'\n",
    "orders_path = 'converted_dataset/codice_galattico/Codice Galattico.txt'\n",
    "\n",
    "with open(path, 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "with open(orders_path, 'r') as f:\n",
    "    text_orders = f.read()\n",
    "\n",
    "splitted_text = text.split('## Menu')\n",
    "\n",
    "## First section\n",
    "request = f\"\"\"Segui attentamente queste istruzioni. Devi estrarre le seguenti informazioni dal <DOCUMENTO> che ti fornirò.\n",
    "Crea un file JSON, ovvero una lista di dizionari, uno per ogni ricetta, composto da 3 chiavi:\n",
    "- *chef*: stringa\n",
    "- *pianeta*: stringa\n",
    "- *ristorante*: stringa\n",
    "- *skills*: lista. Il primo elemento è una skill/competenza, il secondo elemento è un numero intero. A volte un numero può essere rappresentato da un numero romano o altro formato. Convertilo sempre in numero arabo intero. \n",
    "Se un valore non è presente, scrivi \"none\" come valore.\n",
    "\n",
    "<DOCUMENTO>: \"{splitted_text[0]}\"\n",
    "\"\"\"\n",
    "\n",
    "output_0 = chat(request)\n",
    "output_0 = output_0.split('```')[1]\n",
    "output_0 = output_0.replace('json', '')\n",
    "output_0 = json.loads(output_0)\n",
    "print(output_0)\n",
    "\n",
    "## Second section\n",
    "request = f\"\"\"Segui attentamente queste istruzioni. Devi estrarre le seguenti informazioni dal <DOCUMENTO> che ti fornirò.\n",
    "Crea un file JSON, ovvero una lista di dizionari, uno per ogni ricetta, composto da 5 chiavi:\n",
    "- *nome_ricetta*\n",
    "- *ingredienti*\n",
    "- *tecniche*\n",
    "- *descrizione*\n",
    "- *ordine_riferimento*: questo dato non è un numero, bensì un valore che fa riferimento a ordini professionali. Trovi degli esempi all'interno del documento <DOCUMENTO ORDINI>. Spesso questo valore non è presente o è indicato da un'immagine.\n",
    "Se un valore non è presente, scrivi \"none\" come valore.\n",
    "\n",
    "<DOCUMENTO>: \"{splitted_text[1]};\n",
    "<DOCUMENTO ORDINI> \"{text_orders}\"\n",
    "\"\"\"\n",
    "\n",
    "output_1 = chat(request)\n",
    "if type(output_1).__name__ == 'str':\n",
    "    output_1 = output_1.split('```')[1]\n",
    "    output_1 = output_1.replace('json', '')\n",
    "    output_1 = json.loads(output_1)\n",
    "print(output_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nome_ricetta': 'Il Ricordo del Fuoco Celeste',\n",
       "  'ingredienti': ['Farina di Nettuno',\n",
       "   'Carne di Drago',\n",
       "   'Lattuga Namecciana',\n",
       "   'Salsa Szechuan',\n",
       "   'Shard di Materia Oscura',\n",
       "   'Uova di Fenice',\n",
       "   'Spaghi del Sole'],\n",
       "  'tecniche': ['Amalgamazione Sintetica Molecolare',\n",
       "   'Ebollizione Magneto-Cinetica Pulsante',\n",
       "   'Cryo-Tessitura Energetica Polarizzata'],\n",
       "  'descrizione': \"Un piatto che combina sapori e tecniche avanzate per creare un'esperienza culinaria unica.\",\n",
       "  'ordine_riferimento': 'none'},\n",
       " {'nome_ricetta': 'Sinfonia dei Ricordi Celesti',\n",
       "  'ingredienti': ['Carne di balena spaziale',\n",
       "   'Granuli di nebbia arcobaleno',\n",
       "   'Impasto gravitazionale vorticoso'],\n",
       "  'tecniche': ['Spore quantiche',\n",
       "   'Vapore termocinetico multiplo',\n",
       "   'Sinergia Elettro-Osmotica Programmabile'],\n",
       "  'descrizione': 'Un viaggio culinario che esplora i sapori come frammenti del passato.',\n",
       "  'ordine_riferimento': 'none'},\n",
       " {'nome_ricetta': 'Sinfonia del Cosmo',\n",
       "  'ingredienti': ['Liane di Plasmodio',\n",
       "   'Funghi Orbitali',\n",
       "   'Fibra di Sintetex',\n",
       "   'Sale Temporale'],\n",
       "  'tecniche': ['Ebollizione Magneto-Cinetica Pulsante',\n",
       "   'Bollitura Termografica a Rotazione Veloce'],\n",
       "  'descrizione': \"Un'opera d'arte culinaria che unisce ingredienti eterei e tecniche futuristiche.\",\n",
       "  'ordine_riferimento': 'none'},\n",
       " {'nome_ricetta': 'Rapsodia dei Ricordi Celesti',\n",
       "  'ingredienti': ['Carne di Xenodonte',\n",
       "   'Carne di Mucca',\n",
       "   'Forno Dinamico Inversionale',\n",
       "   'Lacrime di Andromeda',\n",
       "   'Essenza di Speziaria'],\n",
       "  'tecniche': ['Marinatura Sotto Zero a Polarità Inversa',\n",
       "   'Cryo-Tessitura Energetica Polarizzata'],\n",
       "  'descrizione': 'Un viaggio gastronomico che combina sapori e memorie.',\n",
       "  'ordine_riferimento': 'none'},\n",
       " {'nome_ricetta': 'Il Simposio degli Infiniti Ricordi',\n",
       "  'ingredienti': ['Pane degli Abissi',\n",
       "   'Carne di Balena spaziale',\n",
       "   'Cristalli di Nebulite',\n",
       "   'Uova di Fenice'],\n",
       "  'tecniche': ['Microonde Entropiche Sincronizzate',\n",
       "   'Cryo-Tessitura Energetica Polarizzata'],\n",
       "  'descrizione': \"Un'opera d'arte culinaria che intreccia sapientemente ogni angolo dell'universo.\",\n",
       "  'ordine_riferimento': 'none'},\n",
       " {'nome_ricetta': 'Viaggio dei Ricordi Stellari',\n",
       "  'ingredienti': ['Gnocchi del Crepuscolo',\n",
       "   'Liane di Plasmodio',\n",
       "   'Granuli di Nebbia Arcobaleno',\n",
       "   'Shard di Prisma Stellare',\n",
       "   'Plasma Vitale'],\n",
       "  'tecniche': ['Bollitura Termografica a Rotazione Veloce',\n",
       "   'Sinergia Elettro-Osmotica Programmabile',\n",
       "   'Cryo-Tessitura Energetica Polarizzata'],\n",
       "  'descrizione': 'Un viaggio culinario che esplora i sapori e le memorie.',\n",
       "  'ordine_riferimento': 'none'},\n",
       " {'nome_ricetta': 'Sinfonia Crepuscolare',\n",
       "  'ingredienti': ['Gnocchi del Crepuscolo', 'Pane di Luce', 'Petali di Eco'],\n",
       "  'tecniche': ['Grigliatura Eletro-Molecolare a Spaziatura Variabile',\n",
       "   'Sinergia Elettro-Osmotica Programmabile'],\n",
       "  'descrizione': \"Un'esperienza culinaria che trascende il semplice nutrimento.\",\n",
       "  'ordine_riferimento': 'none'},\n",
       " {'nome_ricetta': 'Sinfonia Celestiale dei Ricordi',\n",
       "  'ingredienti': ['Biscotti della Galassia',\n",
       "   'Farina di Nettuno',\n",
       "   'Spaghi del Sole',\n",
       "   'Idra',\n",
       "   'Lacrime di Unicorno'],\n",
       "  'tecniche': ['Impasto a Campi Magnetici Dualistici',\n",
       "   'Cottura con Microonde Entropiche Sincronizzate'],\n",
       "  'descrizione': 'Un viaggio culinario attraverso le stelle.',\n",
       "  'ordine_riferimento': 'none'},\n",
       " {'nome_ricetta': 'Sfere del Ricordo Astrale',\n",
       "  'ingredienti': ['Carne di Drago',\n",
       "   'Liane di Plasmodio',\n",
       "   'Foglie di Mandragora',\n",
       "   'Polvere di Pulsar'],\n",
       "  'tecniche': ['Marinatura Sotto Zero a Polarità Inversa',\n",
       "   'Bollitura Termografica a Rotazione Veloce'],\n",
       "  'descrizione': 'Un piatto che risveglia memorie e trasporta tra galassie di gusto e nostalgia.',\n",
       "  'ordine_riferimento': 'none'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nome_ricetta': 'Rapsodia dei Ricordi Celesti',\n",
       " 'ingredienti': ['Carne di Xenodonte',\n",
       "  'Carne di Mucca',\n",
       "  'Forno Dinamico Inversionale',\n",
       "  'Lacrime di Andromeda',\n",
       "  'Essenza di Speziaria'],\n",
       " 'tecniche': ['Marinatura Sotto Zero a Polarità Inversa',\n",
       "  'Cryo-Tessitura Energetica Polarizzata'],\n",
       " 'descrizione': 'Un viaggio gastronomico che combina sapori e memorie.',\n",
       " 'ordine_riferimento': 'none'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Store (Chroma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "filename = \"converted_dataset/Anima Cosmica.txt\"\n",
    "\n",
    "loader = TextLoader(filename)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ibm import WatsonxEmbeddings\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes\n",
    "\n",
    "parameters = {\n",
    "    \"decoding_method\": \"sample\",\n",
    "    \"max_new_tokens\": 100,\n",
    "    \"min_new_tokens\": 1,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 1,\n",
    "}\n",
    "\n",
    "embeddings = WatsonxEmbeddings(\n",
    "    model_id=\"ibm/slate-30m-english-rtrvr\",\n",
    "    url=ENDPOINT_URL\n",
    "    apikey=API_KEY\n",
    "    project_id=PROJECT_ID,\n",
    "    params = parameters\n",
    "    )\n",
    "\n",
    "docsearch = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import os\n",
    "\n",
    "# Modello per gli embedding\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Path dei documenti\n",
    "input_dir = \"converted_dataset/\"\n",
    "texts = []\n",
    "\n",
    "# Legge i file e li suddivide in chunk\n",
    "for file_name in os.listdir(input_dir):\n",
    "    with open(os.path.join(input_dir, file_name), 'r', encoding='utf-8') as file:\n",
    "        texts.append(file.read())\n",
    "\n",
    "# Generazione degli embedding\n",
    "embeddings = model.encode(texts)\n",
    "\n",
    "# Creazione dell'indice FAISS\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "# Salvataggio dell'indice\n",
    "faiss.write_index(index, \"indice_faiss.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Import document\n",
    "pdf_loader = PyPDFLoader('data_pdfreader/bando.pdf')\n",
    "documents = pdf_loader.load()\n",
    "\n",
    "# Split document\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# Populate vector store\n",
    "vectordb = Chroma.from_documents(\n",
    " documents=splits,\n",
    " embedding=OpenAIEmbeddings(),\n",
    " persist_directory='./data/memory'\n",
    ")\n",
    "\n",
    "vectordb.persist()\n",
    "\n",
    "## Request\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(model_name=\"gpt-4\", temperature=0.2),\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Riassumi il contenuto del documento.\\\"\\\"\\\"\"\n",
    "result = qa_chain.invoke({'query': question})\n",
    "\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I RISULTATI NON SONO BUONI, MEGLIO CREARE UN DB PERSONALE (Maggiore Valore) ##\n",
    "\n",
    "from libraries.bandit.bandit.functions import *\n",
    "\n",
    "prompt = f\"What is the average round for a single Pre-Seed Deeptech startup in Italy?\"\n",
    "\n",
    "rnd, _ = ask_langchain(prompt)\n",
    "\n",
    "request = f\"\"\"\n",
    "1. Estrai solo il <numero> dal seguente <testo>: \"{rnd}\".\n",
    "2. Il numero deve essere in formato intero: ad esempio, se nel <testo> trovi scritto \"€0,4 milioni\", tu scrivi \"400000\". Non usare simboli di valuta. Formattalo come numero intero;\n",
    "3. Crea un file JSON, ovvero un dizionario composto da due chiavi: \"key\" e \"value\";\n",
    "3.1. \"key\" sarà sempre uguale a \"round\", mentre \"value\" sarà il <numero> che è stato estratto in precedenza.\"\"\"\n",
    "\n",
    "rnd_num, _ = chat([request], temperature = 0.0, format=\"json\")\n",
    "rnd_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libraries.bandit.bandit.functions import *\n",
    "from pypdf import PdfReader\n",
    "import textwrap\n",
    "\n",
    "# Set the width at which to wrap the text\n",
    "width = 100\n",
    "\n",
    "# creating a pdf reader object \n",
    "reader = PdfReader('data_pdfreader/bando.pdf') \n",
    "  \n",
    "# creating a page object \n",
    "text = \"\"\n",
    "for p in range(len(reader.pages)):\n",
    "    pageObj = reader.pages[p]\n",
    "    text += pageObj.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\"\", f\"BANDO: \\\"\\\"\\\"{text}\\\"\\\"\\\". Estrai solamente le macrosezioni *numerate* del documento senza nessun'altra informazione. Non scrivere le sottosezioni né nessun altra informazione non pertinente al nome della sezione. Forniscimi un elenco numerato dei vari punti. Non voglio nessuna frase introduttiva, voglio solo un elenco numerato.\"]\n",
    "\n",
    "ans, _ = chat(prompt, model=\"gpt-4-turbo\", temperature=0.0, max_tokens=4096, frequency_penalty=0.0, presence_penalty=0.0)\n",
    "wrapped_text = textwrap.fill(ans, width=width)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\"\", f\"BANDO: \\\"\\\"\\\"{text}\\\"\\\"\\\". Estrai solamente le macrosezioni *numerate* del documento senza nessun'altra informazione. Non scrivere le sottosezioni né nessun altra informazione non pertinente al nome della sezione. Forniscimi un elenco numerato dei vari punti. Non voglio nessuna frase introduttiva, voglio solo un elenco numerato.\"]\n",
    "\n",
    "ans, _ = chat(prompt, model=\"gpt-4-turbo\", temperature=0.0, max_tokens=4096, frequency_penalty=0.0, presence_penalty=0.0)\n",
    "wrapped_text = textwrap.fill(ans, width=width)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install crewai\n",
    "!pip install langchain_openai\n",
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from crewai_tools import PDFSearchTool\n",
    "from crewai_tools  import tool\n",
    "from crewai import Crew\n",
    "from crewai import Task\n",
    "from crewai import Agent\n",
    "from crewai.tools import BaseTool\n",
    "from pydantic import Field\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "SERPER_API_KEY=os.getenv(\"SERPER_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "Router_Agent = Agent(\n",
    "  role='Router',\n",
    "  goal='Route user question to a vectorstore or web search',\n",
    "  backstory=(\n",
    "    \"You are an expert at routing a user question to a vectorstore or web search .\"\n",
    "    \"Use the vectorstore for questions on transformer or differential transformer.\"\n",
    "    \"use web-search for question on latest news or recent topics.\"\n",
    "    \"use generation for generic questions otherwise\"\n",
    "  ),\n",
    "  verbose=True,\n",
    "  allow_delegation=False,\n",
    "  llm=llm,\n",
    ")\n",
    "Retriever_Agent = Agent(\n",
    "role=\"Retriever\",\n",
    "goal=\"Use the information retrieved from the vectorstore to answer the question\",\n",
    "backstory=(\n",
    "    \"You are an assistant for question-answering tasks.\"\n",
    "    \"Use the information present in the retrieved context to answer the question.\"\n",
    "    \"You have to provide a clear concise answer.\"\n",
    "),\n",
    "verbose=True,\n",
    "allow_delegation=False,\n",
    "llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GoogleSerperAPIWrapper\n",
    "\n",
    "class SearchTool(BaseTool):\n",
    "    name: str = \"Search\"\n",
    "    description: str = \"Useful for search-based queries. Use this to find current information about markets, companies, and trends.\"\n",
    "    search: GoogleSerperAPIWrapper = Field(default_factory=GoogleSerperAPIWrapper)\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"Execute the search query and return results\"\"\"\n",
    "        try:\n",
    "            return self.search.run(query)\n",
    "        except Exception as e:\n",
    "            return f\"Error performing search: {str(e)}\"\n",
    "class GenerationTool(BaseTool):\n",
    "    name: str = \"Generation_tool\"\n",
    "    description: str = \"Useful for generic-based queries. Use this to find  information based on your own knowledge.\"\n",
    "    #llm: ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "      llm=ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "      \"\"\"Execute the search query and return results\"\"\"\n",
    "      return llm.invoke(query)\n",
    "generation_tool=GenerationTool()\n",
    "web_search_tool = SearchTool()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
